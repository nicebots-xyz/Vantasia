import anthropic
import orjson
import json
import xml.etree.ElementTree as ET
import openai

from ..config.settings import ANTHROPIC_PROMPT, ANTHROPIC_KEY, openaiClient, OPENAI_PROMPT


from anthropic import AsyncAnthropic, HUMAN_PROMPT, AI_PROMPT
from anthropic.types import Completion

anthropic = AsyncAnthropic(api_key=ANTHROPIC_KEY, max_retries=5)


def json_to_xml(json_obj):
    root = ET.Element("items")

    for key, value in json_obj.items():
        item = ET.SubElement(root, "item", idx=str(key))
        item.text = value

    return ET.tostring(root, encoding="unicode", method="xml")


def xml_to_json(xml_data):
    root = ET.fromstring(xml_data)
    activities = []

    for act in root.findall("act"):
        activity = {"title": act.find("t").text, "parts": []}
        parts = act.find("ps")
        for p in parts.findall("p"):
            activity["parts"].append(int(p.text))
        activities.append(activity)

    return json.dumps(activities, indent=4)


async def getBestofs(transcript: str | dict):
    """
    Returns the best completion for the given transcript using the Anthropoc AI model.

    Args:
        transcript (str | dict): The transcript to generate a completion for. If a dictionary is provided, it will be converted to a JSON string.

    Returns:
        dict: The best completion generated by the Anthropoc AI model.
    """
    if isinstance(transcript, str):
        transcript = json.loads(transcript)
    # to xml
    xml_transcript = json_to_xml(transcript)
    prompt = f"{HUMAN_PROMPT} {ANTHROPIC_PROMPT}\n{transcript}{AI_PROMPT}"
    completion: Completion = await anthropic.completions.create(
        max_tokens_to_sample=8192, prompt=prompt, model="claude-instant-1"
    )
    completion = completion.completion
    completion: str
    completion = completion.split("<", 1)[1]
    completion = "<" + completion
    completion = xml_to_json(completion)
    completion = json.loads(completion)
    return completion


async def getBestOfsOAI(transcript: str | dict):
    if isinstance(transcript, dict):
        transcript = json.dumps(transcript)
    messages = [
        {
            "role": "system",
            "content": OPENAI_PROMPT,
        },
        {
            "role": "user",
            "content": transcript,
        },
    ]
    models = openaiClient.models.list()
    completion = await openaiClient.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=messages,
        response_format=openai.types.chat.completion_create_params.ResponseFormat(
            type="json_object"
        ),
        max_tokens=4096,
    )
    response = completion.choices[0].message.content
    print(response)
    response = orjson.loads(response)
    response = response["response"]
    return response
